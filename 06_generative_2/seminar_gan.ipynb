{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion-MNIST GAN\n",
    "Disclaimer: This notebook is an adopted version of [this](https://github.com/mickypaganini/GAN_tutorial) and [this](https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html) tutorials.\n",
    "<img src=\"static/fashion-mnist.png\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "In this tutorial we'll use [Fashion-MNIST dataset](https://github.com/zalandoresearch/fashion-mnist). In short: Fashion-MNIST is like MNIST but with fashion items (shirts, shoes, etc.).\n",
    "\n",
    "Let's setup transforms and dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.FashionMNIST(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    transform=transform,\n",
    "    download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to back from [-1, 1] to [0, 1]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denorm(x):\n",
    "    out = (x + 1) / 2\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Labels: \", np.unique(dataset.train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(dataset.train_labels, bins=np.linspace(0, 9.5, 20))\n",
    "\n",
    "plt.xticks(range(10))\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_images = 5\n",
    "\n",
    "fig, axes = plt.subplots(len(np.unique(dataset.train_labels)), n_images, figsize=(10, 10))\n",
    "# fig.subplots_adjust(wspace=-0.7)\n",
    "\n",
    "for label in np.unique(dataset.train_labels):\n",
    "    axes[label, 0].text(-20, 20, str(label), size=20)\n",
    "    \n",
    "    for image_i, image in enumerate(dataset.train_data.numpy()[dataset.train_labels.numpy() == label][:n_images]):\n",
    "        axes[label, image_i].imshow(image, interpolation='bilinear', cmap='Greys')\n",
    "        axes[label, image_i].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup dataloader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=batch_size, \n",
    "    shuffle=True,\n",
    "    num_workers=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is GAN?\n",
    "\n",
    "GANs are a framework for teaching a DL model to capture the training data’s distribution so we can generate new data from that same distribution. GANs were invented by Ian Goodfellow in 2014 and first\n",
    "described in the paper [Generative Adversarial Nets](https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf). They are made of two distinct models, a *generator* and a *discriminator*. The job of the generator is to spawn ‘fake’ images that look like the training images. The job of the discriminator is to look at an image and output whether or not it is a real training image or a fake image from the generator. During training, the generator is constantly trying to outsmart the discriminator by generating better and better fakes, while the discriminator is working to become a better detective and correctly classify the real and fake images. The equilibrium of this game is when the generator is generating perfect fakes that look as if they came directly from the training data, and the discriminator is left to always guess at 50% confidence that the generator output is real or fake.\n",
    "\n",
    "Now, lets define some notation to be used throughout tutorial starting with the discriminator. Let $x$ be data representing an image. $D(x)$ is the discriminator network which outputs the (scalar) probability that $x$ came from training data rather than the generator. Here, since we are dealing with images the input to $D(x)$ is an image of size 28x28. Intuitively, $D(x)$ should be HIGH when $x$ comes from training data and LOW when $x$ comes from the generator. $D(x)$ can also be thought of as a traditional binary classifier.\n",
    "\n",
    "For the generator’s notation, let $z$ be a latent space vector sampled from a standard normal distribution. $G(z)$ represents the generator function which maps the latent vector $z$ to data-space. The goal of $G$ is to estimate the distribution that the training data comes from ($p_{data}$) so it can generate fake samples from that estimated distribution ($p_g$).\n",
    "\n",
    "So, $D(G(z))$ is the probability (scalar) that the output of the generator $G$ is a real image. As described in Goodfellow’s paper, $D$ and $G$ play a minimax game in which $D$ tries to maximize the probability it correctly classifies reals and fakes ($logD(x)$), and $G$ tries to minimize the probability that $D$ will predict its outputs are fake ($log(1-D(G(x)))$).\n",
    "\n",
    "From the paper, the GAN loss function is\n",
    "\n",
    "\\begin{align}\\underset{G}{\\text{min}} \\underset{D}{\\text{max}}V(D,G) = \\mathbb{E}_{x\\sim p_{data}(x)}\\big[logD(x)\\big] + \\mathbb{E}_{z\\sim p_{z}(z)}\\big[log(1-D(G(x)))\\big]\\end{align}\n",
    "\n",
    "In theory, the solution to this minimax game is where $p_g = p_{data}$, and the discriminator guesses randomly if the inputs are real or fake. However, the convergence theory of GANs is still being actively researched and in reality models do not always"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 (1 point). Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAN consits of two main parts:\n",
    "1. **Generator**: generates images from noise vector\n",
    "2. **Discriminator**: classifies real images from generated (fake) ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator\n",
    "The generator, $G$, is designed to map the latent space vector ($z$) to data-space. Since our data are images, converting $z$ to data-space means ultimately creating a image with the same size as the training images (i.e. 28x28). In practice, this is\n",
    "accomplished through a series of strided two dimensional convolutional transpose layers, but for simplicity we'll use linear model. The output of the generator is fed through a tanh function\n",
    "to return it to the input data range of $[-1,1]$.\n",
    "\n",
    "That's how our generator will work: it takes noise vector of shape **nz**, process it with 5 linear layers (with **256** neurons each) and outputs image (vector of shape **784** = 28x28) pushing it through [Tanh](https://pytorch.org/docs/stable/nn.html#torch.nn.Tanh) activation function. As a nonlinearity we'll use [Leacky ReLU](https://pytorch.org/docs/stable/nn.html#torch.nn.LeakyReLU) with negative slope parameter of **0.2**. Let's implement generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nz = 64\n",
    "\n",
    "G = nn.Sequential(\n",
    "    ## your code here\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator\n",
    "\n",
    "As mentioned, the discriminator, $D$, is a binary classification network that takes an image as input and outputs a scalar probability that the input image is real (as opposed to fake). Here, $D$ takes a 28x28 input image, processes it through a series of linear layers with nonlinearities and outputs the final probability through a Sigmoid activation function.\n",
    "\n",
    "That's how our discriminator will work: it takes image (vector of shape **784** = 28x28), process it with 5 linear layers (with **256** neurons each) and outputs classification score (vector of size 1) pushing it through [Sigmoid](https://pytorch.org/docs/stable/nn.html#torch.nn.Sigmoid) activation function. As a nonlinearity we'll also use [Leacky ReLU](https://pytorch.org/docs/stable/nn.html#torch.nn.LeakyReLU) with negative slope parameter of **0.2**. Let's implement discriminator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator\n",
    "D = nn.Sequential(\n",
    "    ## your code here\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss functions and optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With $D$ and $G$ setup, we can specify how they learn through the loss functions and optimizers. We will use the [Binary Cross Entropy loss](https://pytorch.org/docs/stable/nn.html#torch.nn.BCELoss) function which is defined in PyTorch as:\n",
    "\n",
    "\\begin{align}\\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad l_n = - \\left[ y_n \\cdot \\log x_n + (1 - y_n) \\cdot \\log (1 - x_n) \\right]\\end{align}\n",
    "\n",
    "Notice how this function provides the calculation of both log components in the objective function (i.e. $log(D(x))$ and $log(1-D(G(z)))$). We can specify what part of the BCE equation to use with the $y$ input. This is accomplished in the training loop which is coming up soon, but it is important to understand how we can choose which component we wish to calculate just by changing $y$ (i.e. GT labels).\n",
    "\n",
    "Next, we define our real label as 1 and the fake label as 0. These labels will be used when calculating the losses of $D$ and $G$, and this is also the convention used in the original GAN paper. Finally, we set up two separate optimizers, one for $D$ and\n",
    "one for $G$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "d_optimizer = torch.optim.Adam(D.parameters(), lr=0.0003)\n",
    "g_optimizer = torch.optim.Adam(G.parameters(), lr=0.0003)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For keeping track of the generator’s learning progression, we will generate a fixed batch of latent vectors that are drawn from a Gaussian distribution (i.e. fixed_noise) . In the training loop, we will periodically input this fixed_noise into $G$, and over the iterations we will see images form out of the noise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_noise = torch.randn(64, nz).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 (3 points). Train-loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make dirs to store training progress:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"./images\", exist_ok=True)\n",
    "os.makedirs(\"./weights\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch allows you to build **dynamic graphs** in a very intuitive and pythonic way. \n",
    "\n",
    "You should write the training loop yourself, looping through the epochs and the batches.\n",
    "\n",
    "Although this adds additional boilerplate and room for error when compared to libraries like Keras, this dynamic construction gives the flexibility required for exotic train loops that do not fit the `model.fit(...)` paradigm, such as GANs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 200\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for batch_number, (images, _) in enumerate(dataloader):\n",
    "        current_batch_size = images.shape[0]\n",
    "        \n",
    "        # reshape training dataset images from (batch_size, 28, 28) to (batch_size, 28*28) for processing through fully-connected net\n",
    "        images = images.view(current_batch_size, -1).to(device)\n",
    "\n",
    "        # create targets for the discriminator network D (fill it with real_label or fake_label value)\n",
    "        real_labels = ## your code here\n",
    "        fake_labels = ## your code here\n",
    "\n",
    "        # 1) Train discriminator\n",
    "        \n",
    "        # evaluate the discriminator on the real input images\n",
    "        real_scores = ## your code here\n",
    "        \n",
    "        # compute the discriminator loss with respect to the real labels\n",
    "        d_loss_real = criterion(real_scores, real_labels)\n",
    "\n",
    "        # draw random nz-dimensional noise vectors as inputs to the generator network\n",
    "        z = torch.randn(current_batch_size, nz).to(device) # the latents space is nz\n",
    "        \n",
    "        # transform the noise through the generator network to get synthetic images\n",
    "        fake_images = ## your code here\n",
    "        \n",
    "        # evaluate the discriminator on the fake images\n",
    "        fake_scores = ## your code here\n",
    "        \n",
    "        # compute the discriminator loss with respect to the fake labels\n",
    "        d_loss_fake = ## your code here\n",
    "\n",
    "        # backprop + optimize the discriminator\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        \n",
    "        D.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "\n",
    "        # 2) Train generator\n",
    "        \n",
    "        # draw random nz-dimensional noise vectors as inputs to the generator network\n",
    "        z = ## your code here\n",
    "        \n",
    "        # transform the noise through the generator network to get synthetic images\n",
    "        fake_images = ## your code here\n",
    "        \n",
    "        # evaluate the (new) discriminator on the fake images\n",
    "        fake_scores = ## your code here\n",
    "\n",
    "        # compute the cross-entropy loss with \"real\" as target (1s). This is what the G wants to do\n",
    "        g_loss = ## your code here\n",
    "\n",
    "        # backprop + optimize the generator\n",
    "        D.zero_grad()\n",
    "        G.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "\n",
    "        if (batch_number + 1) % 300 == 0:\n",
    "            print('Epoch [%d/%d], Step[%d/%d], d_loss: %.4f, '\n",
    "                  'g_loss: %.4f, Mean D(x): %.2f, Mean D(G(z)): %.2f' \n",
    "                  %(epoch,\n",
    "                    n_epochs,\n",
    "                    batch_number + 1,\n",
    "                    len(dataloader),\n",
    "                    d_loss.item(),\n",
    "                    g_loss.item(),\n",
    "                    real_scores.mean(),\n",
    "                    fake_scores.mean())\n",
    "            )\n",
    "    \n",
    "    # Save fixed noise images\n",
    "    fixed_noise_images = G(fixed_noise)\n",
    "    fixed_noise_images = fixed_noise_images.view(fixed_noise_images.shape[0], 1, 28, 28)\n",
    "    torchvision.utils.save_image(denorm(fixed_noise_images), './images/fixed_noise_images-%0.3d.png' % (epoch + 1))\n",
    "\n",
    "    # Save the trained parameters \n",
    "    torch.save(G.state_dict(), './weights/generator-%0.3d.pkl' % (epoch + 1))\n",
    "    torch.save(D.state_dict(), './weights/discriminator-%0.3d.pkl' % (epoch + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create video from generated images from fixed noise epoch-wise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.call([\n",
    "    'ffmpeg', '-y', '-framerate', '8', '-i', './images/fixed_noise_images-%03d.png', '-r', '30', '-pix_fmt', 'yuv420p',\n",
    "    'fixed_noise_images.mp4'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load your favorite epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.load_state_dict(torch.load('./weights/generator-200.pkl'))\n",
    "D.load_state_dict(torch.load('./weights/discriminator-200.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now let's generate some images from random vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.randn(60000, nz).to(device)\n",
    "fake_images = G(z).detach().cpu().numpy().reshape(60000, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(fake_images[0], cmap='Greys', interpolation='bilinear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's analyze our generated images with cluster analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inertia = []\n",
    "normed_real_images = dataset.train_data.numpy().reshape(len(dataset), -1) / 255. * 2. - 1.\n",
    "for n_clusters in range(2, 15):\n",
    "    model = MiniBatchKMeans(n_clusters=n_clusters)\n",
    "    model.fit(normed_real_images)\n",
    "    inertia.append(model.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inertia_gan = []\n",
    "for n_clusters in range(2, 15):\n",
    "    model = MiniBatchKMeans(n_clusters=n_clusters)\n",
    "    model.fit(fake_images.reshape(60000, -1))\n",
    "    inertia_gan.append(model.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(2, 15), inertia, label='Training Set')\n",
    "plt.plot(range(2, 15), inertia_gan, label='GAN Generated')\n",
    "plt.legend()\n",
    "plt.ylabel('Within-cluster sum of squares')\n",
    "plt.xlabel('Number of clusters');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
